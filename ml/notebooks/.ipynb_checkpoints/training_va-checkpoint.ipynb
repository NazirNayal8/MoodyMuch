{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from models.mobilenetv2 import mobilenetv2\n",
    "from data.affwild2_dataset import AffWild2VADataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from typing import Any\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def store_params(content, name):\n",
    "    f = open(f'params/{name}.pkl','wb')\n",
    "    pickle.dump(content, f)\n",
    "    f.close()\n",
    "\n",
    "def load_params(name):\n",
    "    fl = open(f'params/{name}.pkl', \"rb\")\n",
    "    loaded = pickle.load(fl)\n",
    "    return loaded\n",
    "\n",
    "def store_model(model, name):\n",
    "    torch.save(model.state_dict(), f'./trained_models/{name}.pth')\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'moody_much'\n",
    "cores = 12\n",
    "random_seed(8)\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AffWild2VADataset(train=True, skip=3, split=0.8)\n",
    "valid_dataset = AffWild2VADataset(train=False, skip=3, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 51)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid_num = len(valid_dataset)\n",
    "total_train_num = len(train_dataset)\n",
    "valid_num = int(0.5 * total_valid_num)\n",
    "\n",
    "valid_mask = list(range(valid_num))\n",
    "test_mask = list(range(valid_num, total_valid_num))\n",
    "\n",
    "valid_loader = DataLoader(Subset(valid_dataset, valid_mask), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(Subset(valid_dataset, test_mask), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "small_train_mask = random.sample(range(total_train_num), 2)\n",
    "medium_train_mask = random.sample(range(total_train_num), 5)\n",
    "small_valid_mask = random.sample(range(total_valid_num), 2)\n",
    "\n",
    "small_train_loader = DataLoader(Subset(train_dataset, list(small_train_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "small_valid_loader = DataLoader(Subset(valid_dataset, list(small_valid_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "\n",
    "medium_loader = DataLoader(Subset(train_dataset, list(medium_train_mask)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'epochs': 5,\n",
    "    'pretrained': True,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.0002,\n",
    "    'optimizer': 'adam',\n",
    "    'weight_decay': 4e-5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, data_loader: Any, device: torch.device, comment: str = \"\"):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "    loss_history = []\n",
    "\n",
    "    batch = 128\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for (frames, arousal, valence) in tqdm(data_loader):\n",
    "            \n",
    "            num_frames = len(frames)\n",
    "            for i in range(num_frames // batch):\n",
    "                \n",
    "                l = batch * i\n",
    "                r = min(batch * (i + 1), num_frames)\n",
    "                \n",
    "                frame = frames[l:r]\n",
    "                a = arousal[l:r]\n",
    "                v = valence[l:r]\n",
    "                \n",
    "                frame = frame.to(device)\n",
    "                a = a.to(device)\n",
    "                v = v.to(device)\n",
    "                \n",
    "                a_pred, v_pred = model(frame)\n",
    "                \n",
    "                a_loss = F.mse_loss(a_pred.flatten(start_dim=1), a.flatten(start_dim=1))\n",
    "                v_loss = F.mse_loss(v_pred.flatten(start_dim=1), v.flatten(start_dim=1))\n",
    "                loss = a_loss + v_loss\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "                \n",
    "    avg_loss = total_loss / count\n",
    "    wandb.log({'valid_loss': avg_loss})\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, data_loader, test_loader, device):\n",
    "    \n",
    "    # wandb.watch(model, log=\"all\", log_freq=10)\n",
    "    \n",
    "    full_start = time.time()\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        print(f\"Starting Epoch {i}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        epoch_time = time.time()\n",
    "        num_batches = 0\n",
    "        \n",
    "        batch = 128\n",
    "        count = 0\n",
    "        for (frames, arousal, valence) in tqdm(data_loader):\n",
    "            \n",
    "            num_frames = len(frames)\n",
    "            for i in range(num_frames // batch):\n",
    "                \n",
    "                l = batch * i\n",
    "                r = min(batch * (i + 1), num_frames)\n",
    "                \n",
    "                frame = frames[l:r]\n",
    "                a = arousal[l:r]\n",
    "                v = valence[l:r]\n",
    "                \n",
    "                frame = frame.to(device)\n",
    "                a = a.to(device)\n",
    "                v = v.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                a_pred, v_pred = model(frame)\n",
    "                \n",
    "                a_loss = F.mse_loss(a_pred.flatten(start_dim=1), a.flatten(start_dim=1))\n",
    "                v_loss = F.mse_loss(v_pred.flatten(start_dim=1), v.flatten(start_dim=1))\n",
    "                loss = a_loss + v_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "            \n",
    "\n",
    "                wandb.log({'batch_loss': loss.item()})\n",
    "                print(f\"Finished Epoch {i}\")\n",
    "        \n",
    "        valid_loss = evaluate(model, test_loader, device)\n",
    "        train_loss = evaluate(model, data_loader, device)\n",
    "        \n",
    "        wandb.log({\n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': valid_loss,\n",
    "            'epoch_time_minutes': (time.time() - epoch_time) / 60\n",
    "        })\n",
    "        \n",
    "        if i % 3 == 0:\n",
    "            torch.save(model.state_dict(), 'trained_models/moody_much_checkpoint.pth')\n",
    "        \n",
    "    wandb.log({'full_run_time_minutes': (time.time() - full_start) / 60})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparameters, model=None, model_path=None):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    \n",
    "    with wandb.init(project=project_name, config=hyperparameters):\n",
    "       \n",
    "        config = wandb.config\n",
    "        \n",
    "        if model is None:\n",
    "            print(\"Creating a New Model.\")\n",
    "            model = mobilenetv2()\n",
    "            model.load_state_dict(torch.load('weights/mobilenetv2_128x128-fd66a69d.pth'))\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
    "            \n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "           \n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=cores)    \n",
    "        \n",
    "        train(model, optimizer, config.epochs, train_loader, valid_loader, device)\n",
    "\n",
    "        test_loss = evaluate(model, test_loader, device)\n",
    "        \n",
    "        wandb.log({'test_loss': test_loss})\n",
    "    \n",
    "    return model, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">elated-bush-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nazirnayal98/moody_much\" target=\"_blank\">https://wandb.ai/nazirnayal98/moody_much</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nazirnayal98/moody_much/runs/lqfopduu\" target=\"_blank\">https://wandb.ai/nazirnayal98/moody_much/runs/lqfopduu</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/users/nnayal17/moody_much/MoodyMuch/ml/wandb/run-20210324_155836-lqfopduu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a New Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae1877eeee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 59175<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/users/nnayal17/moody_much/MoodyMuch/ml/wandb/run-20210324_155836-lqfopduu/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/users/nnayal17/moody_much/MoodyMuch/ml/wandb/run-20210324_155836-lqfopduu/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">elated-bush-5</strong>: <a href=\"https://wandb.ai/nazirnayal98/moody_much/runs/lqfopduu\" target=\"_blank\">https://wandb.ai/nazirnayal98/moody_much/runs/lqfopduu</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/data/affwild2_dataset.py\", line 55, in __getitem__\n    face_frames = self.get_face_frames(os.path.join(self.affwild2_videos, self.videos[index]))\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/data/affwild2_dataset.py\", line 84, in get_face_frames\n    detections = self.blazeface.predict_on_image(frame)\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/models/blazeface.py\", line 257, in predict_on_image\n    return self.predict_on_batch(img.unsqueeze(0))[0]\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/models/blazeface.py\", line 288, in predict_on_batch\n    x = x.to(self._device())\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 163, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e70ebd360e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-84b87da66dcb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(hyperparameters, model, model_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b59b1ce63d64>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, data_loader, test_loader, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marousal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/data/affwild2_dataset.py\", line 55, in __getitem__\n    face_frames = self.get_face_frames(os.path.join(self.affwild2_videos, self.videos[index]))\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/data/affwild2_dataset.py\", line 84, in get_face_frames\n    detections = self.blazeface.predict_on_image(frame)\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/models/blazeface.py\", line 257, in predict_on_image\n    return self.predict_on_batch(img.unsqueeze(0))[0]\n  File \"/scratch/users/nnayal17/moody_much/MoodyMuch/ml/models/blazeface.py\", line 288, in predict_on_batch\n    x = x.to(self._device())\n  File \"/kuacc/users/nnayal17/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 163, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n"
     ]
    }
   ],
   "source": [
    "model, test_accuracy = train_model(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(model.to(torch.device('cuda:0')), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nazir_env",
   "language": "python",
   "name": "nazir_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
